# Distancia de Hamming y An√°lisis de Lenguajes

**Ruta:** [üìö Fundamentos de Electr√≥nica](../../../index.md) > [M√≥dulo 6: Fundamentos de Electr√≥nica Digital](../../index.md) > [Sistemas de Representaci√≥n de la Informaci√≥n](../index.md) > [Alfabetos, Lenguajes y Sem√°ntica](index.md)
[‚¨ÖÔ∏è Anterior](propiedades_de_codigos_adyacente_ciclico_saturado.md)

---

**ID:** `1.6.1.1.3`

## üìù Contenido Te√≥rico

### 1. Introducci√≥n

La **distancia de Hamming** es una m√©trica fundamental en teor√≠a de la informaci√≥n y c√≥digos detectores/correctores de errores. Fue introducida por Richard Hamming en 1950 como parte de su trabajo sobre detecci√≥n y correcci√≥n de errores en sistemas de comunicaci√≥n digital.

#### Definici√≥n Formal

> **Definici√≥n**: Sea Œ£ un alfabeto finito. La distancia de Hamming entre dos palabras x, y ‚àà Œ£‚Åø de igual longitud n es:
>
> ```
> d_H(x, y) = |{i : 1 ‚â§ i ‚â§ n, x_i ‚â† y_i}|
> ```
>
> Es decir, el n√∫mero de posiciones en las que x e y difieren.

#### Ejemplo Introductorio

Para cadenas binarias:

```
    Posici√≥n (columnas):
    0  1  2  3  4  5  6
x = 1  0  1  1  0  1  0
y = 1  0  0  1  1  1  0
    ‚úì ‚úì  ‚úó  ‚úì ‚úó  ‚úì  ‚úì d_H(x,y) = 2
    Posici√≥n (columnas):
    0  1  2  3  4  5  6
w = 1  0  2  9  8  7  0
z = 1  0  0  9  3  7  0
    ‚úì ‚úì  ‚úó  ‚úì ‚úó  ‚úì  ‚úì d_H(w,z) = 2
```

d_H(x, y) = 2 (difieren en las posiciones 2 y 4)

### 2. Propiedades Matem√°ticas

#### 2.1 La Distancia de Hamming es una Distancia M√©trica

**Lema 1**: Aditividad de la distancia de Hamming en subpalabras de ancho fijho de $n$ d√≠gitos, con subdivisiones de longitud $n-1$ d√≠gitos y $1$ d√≠gitos.

```Lema
Sea $\Sigma$ un alfabeto finito.
Sea $k \in \SetNat$
Sea ${\Sigma}^k$ el conjunto de todas las palabras de longitud $k$ sobre el alfabeto $\Sigma$.
$‚àÄ x y ‚àà {\Sigma}^k$, sean $x = x_{0} ¬∑ x_{[1:k-1]}$ y $y = y_{0} ¬∑ y_{[1:k-1]}$ se cumple que:
    $d_H(x, y) = d_H(x_{0}, y_{0}) + d_H(x_{[1:k-1]}, y_{[1:k-1]})$
```

**Demostraci√≥n**:

```Proof
Sean $x ‚àà {\Sigma}^k$ y $y ‚àà {\Sigma}^k$ dos palabras de longitud $k$.
Caso base: k = 0
    Si k = 0, entonces x = Œµ y y = Œµ (palabra vac√≠a).
    Luego:
        d_H(x, y) = d_H(Œµ, Œµ) = 0
        d_H(x_{0}, y_{0}) + d_H(x_{[1:k-1]}, y_{[1:k-1]}) = d_H(Œµ, Œµ) + d_H(Œµ, Œµ) = 0 + 0 = 0 ‚úì
    
    Por tanto, el caso base k=0 se cumple.
Caso base: k = 1
    Si k = 1, entonces x = x_{0} y y = y_{0}.
    Luego:
        d_H(x, y) = d_H(x_{0}, y_{0}) + d_H(x_{[1:0]}, y_{[1:0]}) 
                  = d_H(x_{0}, y_{0}) + d_H(Œµ, Œµ) 
                  = d_H(x_{0}, y_{0}) + 0 
                  = d_H(x, y)  ‚úì
    
    Por tanto, el caso base k=1 se cumple.
Hip√≥tesis de inducci√≥n:
    Supongamos que para k = t > 1 se cumple que:
        $‚àÄ x y ‚àà {\Sigma}^t$, sean $x = x[0] ¬∑ x[1:t-1]$ y $y = y[0] ¬∑ y[1:t-1]$ se cumple que:
            $d_H(x, y) = d_H(x[0], y[0]) + d_H(x[1:t-1], y[1:t-1])$
Paso inductivo:
    Debemos demostrar que para k = t + 1 se cumple la propiedad.
    
    Sean $x ‚àà {\Sigma}^{t+1}$ y $y ‚àà {\Sigma}^{t+1}$ dos palabras de longitud $t + 1$.
    Entonces $x = x[0] ¬∑ x[1:t]$ y $y = y[0] ¬∑ y[1:t]$.
    
    Por definici√≥n de distancia de Hamming sobre palabras concatenadas:
    Las posiciones de x e y son:
      - Posici√≥n 0: x[0] vs y[0]
      - Posiciones 1 a t: x[1:t] vs y[1:t]
    
    Luego:
        d_H(x, y) = d_H(x[0] ¬∑ x[1:t], y[0] ¬∑ y[1:t]) # Definici√≥n de la concatenaci√≥n
                  = |{i : 0 ‚â§ i ‚â§ t, (x[0]¬∑x[1:t])·µ¢ ‚â† (y[0]¬∑y[1:t])·µ¢}| # Definici√≥n de d_H
    
    Particionamos el conjunto de √≠ndices {0, 1, ..., t} = {0} ‚à™ {1, 2, ..., t} (disjuntos).
    Por propiedades de indexaci√≥n de concatenaci√≥n:
      - (x[0]¬∑x[1:t])‚ÇÄ = x[0]  y  (y[0]¬∑y[1:t])‚ÇÄ = y[0]
      - Para i ‚â• 1: (x[0]¬∑x[1:t])·µ¢ = x[1:t]·µ¢‚Çã‚ÇÅ  y  (y[0]¬∑y[1:t])·µ¢ = y[1:t]·µ¢‚Çã‚ÇÅ
    
    Por tanto:
                  = |{0 : x[0] ‚â† y[0]}| + |{i : 1 ‚â§ i ‚â§ t, x[1:t]·µ¢‚Çã‚ÇÅ ‚â† y[1:t]·µ¢‚Çã‚ÇÅ}| # Partici√≥n disjunta
    
    Aplicamos la propiedad fundamental: |A ‚à™ B| = |A| + |B| para conjuntos disjuntos.
    Observamos que:
      - |{0 : x[0] ‚â† y[0]}| = d_H(x[0], y[0])  [x[0], y[0] son s√≠mbolos √∫nicos]
      - |{i : 1 ‚â§ i ‚â§ t, x[1:t]·µ¢‚Çã‚ÇÅ ‚â† y[1:t]·µ¢‚Çã‚ÇÅ}| = d_H(x[1:t], y[1:t])  [por def. de d_H sobre palabras]
    
    Por tanto:
                  = d_H(x[0], y[0]) + d_H(x[1:t], y[1:t])  ‚úì
    
    **Observaci√≥n**: Este resultado muestra que la concatenaci√≥n de palabras es un homomorfismo 
    respecto a la descomposici√≥n aditiva de la distancia de Hamming:
        d_H(u¬∑v, u'¬∑v') = d_H(u, u') + d_H(v, v')  cuando |u| = |u'| y |v| = |v'|
    
    Por tanto, el paso inductivo se cumple.
```

**Teorema 1**: La distancia Hamming de las subpalabras de ancho fijo menor que $n$ es estrictamente aditiva.

```Teorema
${\Sigma}^k$ es el conjunto de todas las palabras de longitud $k ‚àà \SetNat$ sobre el alfabeto $\Sigma$.
Sean $n, m ‚àà \SetNat$ con $n+m=k$
Sean $x, y ‚àà {\Sigma}^k$ dos palabras de longitud $k$.
Sean $x = x[0:n-1] ¬∑ x[n:k-1]$ y $y = y[0:n-1] ¬∑ y[n:k-1]$
Entonces: d_H(x, y) = d_H(x[0:n-1], y[0:n-1]) + d_H(x[n:k-1], y[n:k-1])
```

**Demostraci√≥n**:

```Proof
Lo demostraremos por inducci√≥n sobre $k$.

Caso base: k = 1
  Si k = 1, entonces n = 0 y m = 1, o bien n = 1 y m = 0.
  
  ‚Ä¢ Subcaso n = 0, m = 1:
      Entonces x = Œµ ¬∑ x[0] = x[0] y y = Œµ ¬∑ y[0] = y[0]
      Luego:
        d_H(x, y) = d_H(Œµ, Œµ) + d_H(x[0], y[0])
                  = 0 + d_H(x[0], y[0])
                  = d_H(x, y)  ‚úì
  
  ‚Ä¢ Subcaso n = 1, m = 0:
      Entonces x = x[0] ¬∑ Œµ = x[0] y y = y[0] ¬∑ Œµ = y[0]
      Luego:
        d_H(x, y) = d_H(x[0], y[0]) + d_H(Œµ, Œµ)
                  = d_H(x, y) + 0
                  = d_H(x, y)  ‚úì
  
  Por tanto, el caso base k=1 se cumple.
Caso base: k = 2
  Si k = 2, entonces n + m = 2, lo que implica (n=0, m=2), (n=1, m=1) o (n=2, m=0).
  Los casos n=0 y n=2 son triviales (ya cubiertos por k=1).
  
  ‚Ä¢ Subcaso no trivial: n = 1, m = 1:
      Sean x = x‚ÇÄx‚ÇÅ y y = y‚ÇÄy‚ÇÅ dos palabras de longitud 2.
      La descomposici√≥n es: x = x‚ÇÄ ¬∑ x‚ÇÅ y y = y‚ÇÄ ¬∑ y‚ÇÅ
      
      Por definici√≥n de d_H:
        d_H(x, y) = |{i ‚àà {0,1} : x·µ¢ ‚â† y·µ¢}|
      
      Analizamos por casos:
        - Si x‚ÇÄ = y‚ÇÄ y x‚ÇÅ = y‚ÇÅ: entonces d_H(x,y) = 0
          d_H(x‚ÇÄ, y‚ÇÄ) + d_H(x‚ÇÅ, y‚ÇÅ) = 0 + 0 = 0 ‚úì
        
        - Si x‚ÇÄ ‚â† y‚ÇÄ y x‚ÇÅ = y‚ÇÅ: entonces d_H(x,y) = 1
          d_H(x‚ÇÄ, y‚ÇÄ) + d_H(x‚ÇÅ, y‚ÇÅ) = 1 + 0 = 1 ‚úì
        
        - Si x‚ÇÄ = y‚ÇÄ y x‚ÇÅ ‚â† y‚ÇÅ: entonces d_H(x,y) = 1
          d_H(x‚ÇÄ, y‚ÇÄ) + d_H(x‚ÇÅ, y‚ÇÅ) = 0 + 1 = 1 ‚úì
        
        - Si x‚ÇÄ ‚â† y‚ÇÄ y x‚ÇÅ ‚â† y‚ÇÅ: entonces d_H(x,y) = 2
          d_H(x‚ÇÄ, y‚ÇÄ) + d_H(x‚ÇÅ, y‚ÇÅ) = 1 + 1 = 2 ‚úì
      
      En todos los casos: d_H(x, y) = d_H(x‚ÇÄ, y‚ÇÄ) + d_H(x‚ÇÅ, y‚ÇÅ)
  
  Por tanto, el caso base k=2 se cumple para todas las descomposiciones.

Hip√≥tesis de inducci√≥n:
  Supongamos que para k = t ‚â• 2 se cumple que la distancia de Hamming 
  es exactamente aditiva para toda descomposici√≥n n + m = t.

Paso inductivo (inducci√≥n sobre t):
  Debemos demostrar que para k = t + 1, con n + m = t + 1, se cumple la propiedad.
  
  Demostraremos esto por inducci√≥n sobre n (longitud del prefijo):
  
    Caso base (n = 0):
      Si n = 0, entonces m = t + 1, y las palabras x, y tienen longitud k = t + 1.
      
      La partici√≥n es:
        x = x[0:n-1] ¬∑ x[n:k-1] = x[0:-1] ¬∑ x[0:t] = Œµ ¬∑ x[0:t]
        y = y[0:n-1] ¬∑ y[n:k-1] = y[0:-1] ¬∑ y[0:t] = Œµ ¬∑ y[0:t]
      
      Nota: x[0:t] representa x[0], x[1], ..., x[t], que tiene longitud t+1.
            Como k = t+1, entonces x[0:t] = x (la palabra completa).
            An√°logamente, y[0:t] = y.
      
      Por tanto:
        d_H(x, y) = d_H(Œµ ¬∑ x[0:t], Œµ ¬∑ y[0:t])
                  = d_H(Œµ, Œµ) + d_H(x[0:t], y[0:t])    [por aditividad]
                  = 0 + d_H(x, y)                       [pues x[0:t] = x, y[0:t] = y]
                  = d_H(x, y)  ‚úì
    
    Caso base (n = 1):
      Si n = 1, entonces m = t, y las palabras x, y tienen longitud k = t + 1.
      
      La partici√≥n es:
        x = x[0:n-1] ¬∑ x[n:k-1] = x[0:0] ¬∑ x[1:t] = x[0] ¬∑ x[1:t]
        y = y[0:n-1] ¬∑ y[n:k-1] = y[0:0] ¬∑ y[1:t] = y[0] ¬∑ y[1:t]
      
      Nota: x[0:t] representa x[0], x[1], ..., x[t], que tiene longitud t+1.
            Como k = t+1, entonces x[0:t] = x (la palabra completa).
            An√°logamente, y[0:t] = y.
      
      Por tanto:
        d_H(x, y) = d_H(x[0] ¬∑ x[1:t], y[0] ¬∑ y[1:t])
                  = d_H(x[0], y[0]) + d_H(x[1:t], y[1:t])    [por aditividad]
                  = d_H(x[0], y[0]) + d_H(x[1:t], y[1:t])    [pues x[0:t] = x, y[0:t] = y]
                  = d_H(x[0], y[0]) + d_H(x[1:s-1], y[1:s-1]) + d_H(x[s:t], y[s:t])  [por HI sobre k]
                  = d_H(x[0:s-1], y[0:s-1]) + d_H(x[s:t], y[s:t])  [por HI sobre k]
                  = d_H(x, y)  ‚úì

    Caso base (n = t):
      Si n = t entonces m = 1, y las palabras x, y tienen longitud k = t + 1.
      
      La partici√≥n es:
        x = x[0:n-1] ¬∑ x[n:k-1] = x[0:t-1] ¬∑ x[t:t] = x[0:t-1] ¬∑ x[t]
        y = y[0:n-1] ¬∑ y[n:k-1] = y[0:t-1] ¬∑ y[t:t] = y[0:t-1] ¬∑ y[t]
      
      Nota: x[0:t] representa x[0], x[1], ..., x[t], que tiene longitud t+1.
            Como k = t+1, entonces x[0:t-1] ¬∑ x[t] = x (la palabra completa).
            An√°logamente, y[0:t-1] ¬∑ y[t] = y.
      
      Por tanto:
        d_H(x, y) = d_H(x[0:t-1] ¬∑ x[t], y[0:t-1] ¬∑ y[t])
                  = d_H(x[0:t-1], y[0:t-1]) + d_H(x[t], y[t])    [por aditividad]
                  = d_H(x[0:s-1], y[0:s-1]) + d_H(x[s:t-1], y[s:t-1]) + d_H(x[t], y[t]) [por HI sobre k]
                  = d_H(x[0:s-1], y[0:s-1]) + d_H(x[s:t], y[s:t])  [por HI sobre k]
                  = d_H(x, y)  ‚úì

    Hip√≥tesis inductiva (sobre n):
      Supongamos que para n = s se cumple la propiedad cuando s + m = t + 1
    
    Paso inductivo (n = s + 1):
      Sea n = s + 1 y m tal que (s + 1) + m = t + 1, es decir, m = t - s
      
      Entonces:
        x = x[0:s-1] ¬∑ x[s] ¬∑ x[s+1:t]
        y = y[0:s-1] ¬∑ y[s] ¬∑ y[s+1:t]
      
      Por la hip√≥tesis inductiva sobre k (aplicada a k = t):
        d_H(x[0:s-1] ¬∑ x[s:t], y[0:s-1] ¬∑ y[s:t]) = d_H(x[0:s-1], y[0:s-1]) + d_H(x[s:t], y[s:t])
      
      Y tambi√©n por HI sobre k:
        d_H(x, y) = d_H(x[0:s-1] ¬∑ x[s], y[0:s-1] ¬∑ y[s]) + d_H(x[s+1:t], y[s+1:t])
      
      Sustituyendo:
        d_H(x, y) = d_H(x[0:s-1], y[0:s-1]) + d_H(x[s], y[s]) + d_H(x[s+1:t], y[s+1:t])
                  = d_H(x[0:s], y[0:s]) + d_H(x[s+1:t], y[s+1:t])
      
      Lo cual es exactamente la forma deseada con n = s + 1.  ‚úì
  
  Por inducci√≥n sobre n, la propiedad se cumple para todo n con n + m = t + 1.

Por inducci√≥n sobre k, la propiedad de aditividad se cumple para todo k ‚àà ‚Ñï.  ‚ñ°
```

**Teorema 2**: La distancia de Hamming d_H define una m√©trica sobre Œ£‚Åø.

Para demostrar que d_H es una m√©trica, debemos probar que satisface las tres propiedades de una m√©trica:

##### Propiedad M1: No Negatividad e Identidad

```
‚àÄx, y ‚àà Œ£‚Åø: d_H(x, y) ‚â• 0
‚àÄx, y ‚àà Œ£‚Åø: d_H(x, y) = 0 ‚ü∫ x = y
```

**Demostraci√≥n**:

- **No negatividad**: d_H(x, y) cuenta elementos, por tanto d_H(x, y) ‚â• 0
- **Identidad**:
  - (‚üπ) Si x = y, entonces ‚àÄi: x_i = y_i, luego no hay posiciones diferentes, d_H(x, y) = 0
  - (‚ü∏) Si d_H(x, y) = 0, no hay posiciones diferentes, luego ‚àÄi: x_i = y_i, por tanto x = y
- **Positividad**: Por inducci√≥n, si $x, y ‚àà Œ£^1$, y $x \neq y$ entonces $x_0 ‚â† y_0$. $d_H(x, y) = 1$
  - Hip√≥tesis de inducci√≥n: Supongamos que para $n=k$ se cumple que si $x, y ‚àà Œ£^k$ y $x \neq y$ entonces $d_H(x, y) ‚â• 1$
  - Paso inductivo: Para $n=k+1$, sean $x, y ‚àà Œ£^{k+1}$ y $x \neq y$. Entonces $d_H(x, y) = d_H(x[0:k-1], y[0:k-1]) + d_H(x[k],y[k])$. Hay 3 casos posibles:
    - $x[0:k-1] = y[0:k-1]$, entonces $x[k] \neq y[k]$ y por el caso base $d_H(x[0:k], y[0:k]) = d_H(x[0:k-1],y[0:k-1]) + d_H(x[k],y[k]) = 0 + 1 = 1 \le 1$, luego $d_H(x, y) = d_H(x[0:k], y[0:k]) ‚â• 1$.
    - $x[0:k-1] \neq y[0:k-1]$, entonces por hip√≥tesis de inducci√≥n $d_H(x[0:k-1], y[0:k-1]) ‚â• 1$ y $d_H(x[k],y[k]) \le 0$, luego $d_H(x, y) = d_H(x[0:k], y[0:k]) = d_H(x[0:k-1], y[0:k-1]) + d_H(x[k],y[k]) ‚â• 1 + 0 = 1$.
    -

‚ñ°

##### Propiedad M2: Simetr√≠a

```
‚àÄx, y ‚àà Œ£‚Åø: d_H(x, y) = d_H(y, x)
```

**Demostraci√≥n**:

```
d_H(x, y) = |{i : x_i ‚â† y_i}|
          = |{i : y_i ‚â† x_i}|    (la desigualdad es sim√©trica)
          = d_H(y, x)
```

‚ñ°

##### Propiedad M3: Desigualdad Triangular

```
‚àÄx, y, z ‚àà Œ£‚Åø: d_H(x, z) ‚â§ d_H(x, y) + d_H(y, z)
```

**Demostraci√≥n**:

Sea I_{xy} = {i : x_i ‚â† y_i}, I_{yz} = {i : y_i ‚â† z_i}, I_{xz} = {i : x_i ‚â† z_i}

Para cada posici√≥n i hay tres casos:

1. **x_i = y_i = z_i**: i ‚àâ I_{xy} ‚à™ I_{yz} ‚à™ I_{xz}
2. **Dos son iguales, uno diferente**:
   - Si x_i = y_i ‚â† z_i: entonces i ‚àà I_{yz} ‚à© I_{xz}, pero i ‚àâ I_{xy}
   - Si x_i = z_i ‚â† y_i: entonces i ‚àà I_{xy} ‚à© I_{yz}, pero i ‚àâ I_{xz}
   - Si y_i = z_i ‚â† x_i: entonces i ‚àà I_{xy} ‚à© I_{xz}, pero i ‚àâ I_{yz}
3. **Todos diferentes**: x_i ‚â† y_i ‚â† z_i ‚â† x_i: entonces i ‚àà I_{xy} ‚à© I_{yz}

En todos los casos: Si i ‚àà I_{xz}, entonces i ‚àà I_{xy} ‚à™ I_{yz}

Por tanto: I_{xz} ‚äÜ I_{xy} ‚à™ I_{yz}

Luego: |I_{xz}| ‚â§ |I_{xy} ‚à™ I_{yz}| ‚â§ |I_{xy}| + |I_{yz}|

Es decir: d_H(x, z) ‚â§ d_H(x, y) + d_H(y, z)
‚ñ°

**Conclusi√≥n**: Hemos demostrado que la distancia de Hamming es una m√©trica formal. Esta demostraci√≥n est√° implementada como prueba formal en el sistema de l√≥gica matem√°tica del proyecto (ver secci√≥n de demostraciones formales).

### 3. Distancia M√≠nima de un Lenguaje

#### Definici√≥n

Sea L ‚äÜ Œ£‚Åø un lenguaje (conjunto de palabras de longitud n). La **distancia m√≠nima** de L es:

```
d_min(L) = min{d_H(x, y) : x, y ‚àà L, x ‚â† y}
```

#### Importancia

La distancia m√≠nima determina la **capacidad de detecci√≥n y correcci√≥n de errores**:

| d_min | Capacidad |
|-------|-----------|
| d_min = 1 | No detecta errores (palabras adyacentes) |
| d_min = 2 | Detecta 1 error |
| d_min = 3 | Detecta 2 errores, corrige 1 error |
| d_min = 4 | Detecta 3 errores, corrige 1 error |
| d_min = 2t+1 | Corrige hasta t errores |

**Teorema 2**: Un c√≥digo con distancia m√≠nima d puede:

- **Detectar** hasta d-1 errores
- **Corregir** hasta ‚åä(d-1)/2‚åã errores

#### Ejemplo: C√≥digo de Repetici√≥n Triple

```python
L = {000, 111}  # Alfabeto Œ£ = {0, 1}
d_min(L) = d_H(000, 111) = 3
```

Este c√≥digo puede:

- Detectar hasta 2 errores
- Corregir 1 error (por votaci√≥n mayoritaria)

Ejemplo de correcci√≥n:

```
Enviado:  111
Recibido: 101  (error en posici√≥n 2)
Decodificaci√≥n: 
  d_H(101, 000) = 2
  d_H(101, 111) = 1  ‚Üê m√°s cercano
Resultado: 111 (correcto)
```

### 4. Esferas de Hamming

#### Definici√≥n

La **esfera de Hamming** de radio r centrada en x es:

```
S_r(x) = {y ‚àà Œ£‚Åø : d_H(x, y) ‚â§ r}
```

El conjunto de todas las palabras a distancia como m√°ximo r de x.

#### Volumen de una Esfera

Para el alfabeto binario Œ£ = {0, 1}:

```
|S_r(x)| = Œ£(i=0 to r) C(n, i)
```

donde C(n, i) es el coeficiente binomial.

**Justificaci√≥n**: Hay C(n, i) formas de elegir i posiciones de n para cambiar.

Ejemplo para n=7, r=1:

```
|S_1(x)| = C(7,0) + C(7,1) = 1 + 7 = 8
```

(la palabra original + 7 palabras con 1 bit cambiado)

### 5. Cota de Hamming

**Teorema 3 (Cota de Hamming)**:

Para un c√≥digo C ‚äÜ {0,1}‚Åø con distancia m√≠nima d = 2t+1:

```
|C| ¬∑ Œ£(i=0 to t) C(n, i) ‚â§ 2‚Åø
```

**Interpretaci√≥n**: Las esferas de radio t alrededor de cada palabra c√≥digo no se solapan, y todas deben caber en el espacio {0,1}‚Åø.

**C√≥digo perfecto**: Cuando se alcanza la igualdad, el c√≥digo se llama **perfecto**. Ejemplos:

- C√≥digo de Hamming (7,4): n=7, t=1, |C|=16
- C√≥digo de Golay (23,12): n=23, t=3, |C|=4096

### 6. Aplicaciones Pr√°cticas

#### 6.1 Detecci√≥n de Errores

La distancia de Hamming se usa en:

- **C√≥digos de paridad**: d_min = 2 (detecta 1 error)
- **CRC (Cyclic Redundancy Check)**: detecta r√°fagas de errores
- **Checksums**: verificaci√≥n de integridad

#### 6.2 Correcci√≥n de Errores

C√≥digos correctores:

- **Hamming (7,4)**: 4 bits de datos + 3 de paridad, corrige 1 error
- **Reed-Solomon**: usado en CD, DVD, QR codes
- **Turbo codes**: telecomunicaciones 4G/5G
- **LDPC**: WiFi, televisi√≥n digital

#### 6.3 Bioinform√°tica

Comparaci√≥n de secuencias de ADN:

```
Secuencia 1: ACGTACGT
Secuencia 2: ACGTAGGT
d_H = 2 (diferencias en posiciones 6 y 7)
```

#### 6.4 Procesamiento de Im√°genes

Detecci√≥n de similitud entre im√°genes usando hashing perceptual.

### 7. C√≥digos Gray

Los **c√≥digos Gray** son una aplicaci√≥n especial donde palabras adyacentes tienen d_H = 1.

#### C√≥digo Gray de 3 bits

| Decimal | Binario | Gray |
|---------|---------|------|
| 0 | 000 | 000 |
| 1 | 001 | 001 |
| 2 | 010 | 011 |
| 3 | 011 | 010 |
| 4 | 100 | 110 |
| 5 | 101 | 111 |
| 6 | 110 | 101 |
| 7 | 111 | 100 |

**Propiedad**: Cada transici√≥n cambia exactamente 1 bit.

**Aplicaciones**:

- Encoders rotativos
- Conversi√≥n A/D
- Minimizaci√≥n de errores en transiciones

### 8. Relaci√≥n con C√≥digos de Bloque

Un **c√≥digo de bloque (n, k)** codifica k bits de informaci√≥n en n bits (n > k).

**Tasa de c√≥digo**: R = k/n

**Redundancia**: n - k bits

**Objetivo**: Maximizar R manteniendo d_min grande.

#### Ejemplo: Hamming (7,4)

```
n = 7 bits totales
k = 4 bits de datos
Redundancia = 3 bits de paridad
R = 4/7 ‚âà 0.57
d_min = 3 (corrige 1 error)
```

### 9. Algoritmos de C√°lculo

#### Algoritmo 1: C√°lculo Directo

```python
def hamming_distance(x: str, y: str) -> int:
    """Calcula la distancia de Hamming entre dos cadenas."""
    if len(x) != len(y):
        raise ValueError("Las cadenas deben tener la misma longitud")
    
    return sum(c1 != c2 for c1, c2 in zip(x, y))
```

**Complejidad**: O(n)

#### Algoritmo 2: Usando XOR (para binarias)

```python
def hamming_distance_xor(x: int, y: int) -> int:
    """Distancia de Hamming usando XOR para n√∫meros binarios."""
    xor = x ^ y
    count = 0
    while xor:
        count += xor & 1
        xor >>= 1
    return count
```

**Complejidad**: O(log n)

#### Algoritmo 3: Distancia M√≠nima de un C√≥digo

```python
def min_distance(code: list[str]) -> int:
    """Calcula la distancia m√≠nima de un c√≥digo."""
    n = len(code)
    if n < 2:
        return float('inf')
    
    min_dist = float('inf')
    for i in range(n):
        for j in range(i + 1, n):
            dist = hamming_distance(code[i], code[j])
            min_dist = min(min_dist, dist)
    
    return min_dist
```

**Complejidad**: O(n¬≤ ¬∑ m) donde n = |c√≥digo|, m = longitud de palabra

### 10. Teoremas Avanzados

#### Teorema 4 (Cota de Singleton)

```
|C| ‚â§ |Œ£|^(n-d+1)
```

Para un c√≥digo con distancia m√≠nima d.

#### Teorema 5 (Cota de Plotkin)

Para c√≥digos binarios con d > n/2:

```
|C| ‚â§ 2d / (2d - n)
```

#### Teorema 6 (Cota de Elias-Bassalygo)

Mejora la cota de Hamming para c√≥digos grandes.

### 11. Espacio M√©trico de Hamming

El par (Œ£‚Åø, d_H) forma un **espacio m√©trico**:

**Propiedades topol√≥gicas**:

- Espacio discreto (todas las distancias son enteras)
- M√©trica ultram√©trica si d(x,y) = 1 solo cuando x ‚â† y
- Esferas son conjuntos finitos
- No es un espacio normado (no hay noci√≥n de "longitud")

**Embedding**: El espacio de Hamming puede embeberse en ‚Ñù‚Åø con la m√©trica l‚ÇÅ.

### 12. Comparaci√≥n con Otras M√©tricas

| M√©trica | Definici√≥n | Uso |
|---------|------------|-----|
| **Hamming** | N√∫mero de posiciones diferentes | Cadenas de igual longitud |
| **Levenshtein** | M√≠n. operaciones (ins/del/sust) | Cadenas de distinta longitud |
| **Jaccard** | 1 - |A‚à©B|/|A‚à™B| | Conjuntos |
| **Coseno** | 1 - cos(Œ∏) | Vectores (similitud) |
| **Euclidiana** | ‚àöŒ£(xi-yi)¬≤ | Vectores en ‚Ñù‚Åø |

**Nota**: Hamming es un caso especial de Levenshtein cuando solo se permiten sustituciones.

### 13. Demostraci√≥n Formal Computacional

Este proyecto incluye una **demostraci√≥n formal completa** de que la distancia de Hamming es una m√©trica, implementada en el sistema de l√≥gica matem√°tica:

```bash
cd demos
python demo_hamming_metrica.py
```

El demo demuestra formalmente:

1. ‚úì No negatividad e identidad: d(x,y) ‚â• 0 y d(x,y)=0 ‚ü∫ x=y
2. ‚úì Simetr√≠a: d(x,y) = d(y,x)
3. ‚úì Desigualdad triangular: d(x,z) ‚â§ d(x,y) + d(y,z)

Adem√°s valida las propiedades con ejemplos computacionales sobre cadenas binarias.

**Ubicaci√≥n del c√≥digo**: `core/math_logic_system/` contiene el sistema completo de l√≥gica formal que permite construir y verificar demostraciones matem√°ticas rigurosas.

### Resumen

La distancia de Hamming es fundamental para:

- ‚úÖ Teor√≠a de c√≥digos correctores de errores
- ‚úÖ Detecci√≥n y correcci√≥n autom√°tica de errores
- ‚úÖ Dise√±o de sistemas de comunicaci√≥n robustos
- ‚úÖ Bioinform√°tica y comparaci√≥n de secuencias
- ‚úÖ Criptograf√≠a y hashing

Su caracterizaci√≥n como m√©trica formal garantiza propiedades matem√°ticas s√≥lidas que sustentan su uso en aplicaciones cr√≠ticas.

## üîß Funciones Python Asociadas

### M√≥dulos Implementados

#### 1. `core/formal_languages.py`

Funciones b√°sicas para trabajar con lenguajes formales y distancia de Hamming:

```python
from core.formal_languages import hamming_distance, min_distance_of_language

# Calcular distancia entre dos palabras
d = hamming_distance("10110", "10010")  # 1

# Distancia m√≠nima de un c√≥digo
code = ["000", "111", "101", "010"]
d_min = min_distance_of_language(code)  # 2
```

#### 2. `demos/demo_hamming_metrica.py`

Demostraci√≥n formal completa que prueba que la distancia de Hamming es una m√©trica:

```python
from demos.demo_hamming_metrica import (
    create_metric_space_axioms,
    prove_hamming_is_metric,
    validate_with_examples
)

# Crear sistema de axiomas de espacio m√©trico
axioms = create_metric_space_axioms()

# Demostrar formalmente que Hamming es m√©trica
theorems = prove_hamming_is_metric(axioms)

# Validar con ejemplos
validate_with_examples()
```

**Salida**: Prueba formal paso a paso de cada propiedad m√©trica.

#### 3. `core/math_logic_system/`

Sistema completo de l√≥gica matem√°tica para demostraciones formales:

```python
from core.math_logic_system import (
    AxiomSystem, Proof, Theorem, 
    ProofVerifier, ModusPonens
)

# Crear sistema axiom√°tico
system = AxiomSystem("Espacios M√©tricos", "...")

# Construir demostraci√≥n
proof = Proof(goal, "Hamming es m√©trica")
# ... a√±adir pasos ...

# Verificar correcci√≥n
verifier = ProofVerifier(system)
if verifier.verify(proof):
    print("‚úì Demostraci√≥n v√°lida")
```

### Ejemplos de Uso

#### Ejemplo 1: C√°lculo B√°sico

```python
# Distancia entre cadenas binarias
x = "1011010"
y = "1001011"

d = hamming_distance(x, y)
print(f"Distancia: {d}")  # 3

# Posiciones diferentes
differences = [(i, x[i], y[i]) for i in range(len(x)) if x[i] != y[i]]
print(f"Difieren en: {differences}")
# [(2, '1', '0'), (4, '0', '1'), (6, '0', '1')]
```

#### Ejemplo 2: C√≥digo de Hamming (7,4)

```python
# C√≥digo de Hamming con 16 palabras
hamming_7_4 = [
    "0000000", "1101000", "0110100", "1011100",
    "0011010", "1110010", "0101110", "1000110",
    "0001101", "1100101", "0111001", "1010001",
    "0010111", "1111111", "0100011", "1001011"
]

# Calcular distancia m√≠nima
d_min = min_distance_of_language(hamming_7_4)
print(f"Distancia m√≠nima: {d_min}")  # 3

# Capacidad de correcci√≥n
t = (d_min - 1) // 2
print(f"Corrige hasta {t} errores")  # 1
```

#### Ejemplo 3: Esfera de Hamming

```python
from core.formal_languages import hamming_sphere

# Esfera de radio 1 alrededor de "101"
center = "101"
radius = 1
sphere = hamming_sphere(center, radius)

print(f"S_{radius}({center}) = {sphere}")
# {'101', '001', '111', '100'}

print(f"|S_{radius}({center})| = {len(sphere)}")  # 4
# Verificaci√≥n: C(3,0) + C(3,1) = 1 + 3 = 4 ‚úì
```

#### Ejemplo 4: Correcci√≥n de Errores

```python
def decode_nearest_neighbor(received, code):
    """Decodifica usando el vecino m√°s cercano."""
    min_dist = float('inf')
    closest = None
    
    for codeword in code:
        d = hamming_distance(received, codeword)
        if d < min_dist:
            min_dist = d
            closest = codeword
    
    return closest, min_dist

# C√≥digo de repetici√≥n triple
code = ["000", "111"]

# Palabra recibida con error
received = "101"

decoded, dist = decode_nearest_neighbor(received, code)
print(f"Recibido: {received}")
print(f"Decodificado: {decoded}")  # "111"
print(f"Distancia: {dist}")  # 1
```

#### Ejemplo 5: Verificaci√≥n de Propiedades

```python
from demos.demo_hamming_metrica import validate_metric_properties

# Verificar propiedades m√©tricas con ejemplos aleatorios
words = ["0000", "1111", "1010", "0101"]
validate_metric_properties(words)

# Salida:
# ‚úì No negatividad: d(x,y) ‚â• 0
# ‚úì Identidad: d(x,x) = 0
# ‚úì Simetr√≠a: d(x,y) = d(y,x)
# ‚úì Desigualdad triangular: d(x,z) ‚â§ d(x,y) + d(y,z)
```

### Ejecuci√≥n de Demos

```bash
# Demostraci√≥n formal completa
cd demos
python demo_hamming_metrica.py

# Sistema de l√≥gica matem√°tica
python -c "from core.math_logic_system import PeanoArithmetic; p = PeanoArithmetic(); p.show_axioms()"
```

## üìö Recursos Adicionales

### Referencias Acad√©micas

1. **Hamming, R.W.** (1950). "Error detecting and error correcting codes". *Bell System Technical Journal*, 29(2):147-160.
   - Art√≠culo original que introduce la distancia de Hamming

2. **MacWilliams, F.J. & Sloane, N.J.A.** (1977). *The Theory of Error-Correcting Codes*. North-Holland.
   - Tratado completo sobre c√≥digos correctores

3. **Lin, S. & Costello, D.J.** (2004). *Error Control Coding* (2nd ed.). Prentice Hall.
   - Texto moderno sobre teor√≠a de c√≥digos

4. **Roth, R.M.** (2006). *Introduction to Coding Theory*. Cambridge University Press.
   - Introducci√≥n matem√°tica rigurosa

### Recursos en L√≠nea

- [Wikipedia: Hamming Distance](https://en.wikipedia.org/wiki/Hamming_distance)
- [Stanford CS259: Information Theory](https://web.stanford.edu/class/cs259/)
- [MIT 6.02: Introduction to EECS II (Coding Theory)](https://ocw.mit.edu/)

### Implementaciones de Referencia

- **SciPy**: `scipy.spatial.distance.hamming`
- **NumPy**: C√°lculo vectorizado
- **Hamming**: Librer√≠a especializada en Python

### Material del Proyecto

- **C√≥digo fuente**: `core/formal_languages.py`, `core/math_logic_system/`
- **Demos**: `demos/demo_hamming_metrica.py`
- **Tests**: `tests/test_formal_languages.py`
- **Documentaci√≥n API**: `core/math_logic_system/README.md`

## ‚úÖ Estado de Desarrollo

- [x] Teor√≠a documentada
  - [x] Definici√≥n formal
  - [x] Demostraci√≥n de propiedades m√©tricas
  - [x] Aplicaciones y ejemplos
  - [x] Teoremas avanzados
  - [x] Algoritmos de c√°lculo
  
- [x] Ejemplos a√±adidos
  - [x] C√°lculo b√°sico
  - [x] C√≥digos correctores (Hamming 7,4)
  - [x] Esferas de Hamming
  - [x] Correcci√≥n de errores
  - [x] C√≥digo Gray
  
- [x] Funciones Python implementadas
  - [x] `hamming_distance()` - C√°lculo b√°sico
  - [x] `min_distance_of_language()` - Distancia m√≠nima
  - [x] `hamming_sphere()` - Esfera de radio r
  - [x] `decode_nearest_neighbor()` - Decodificaci√≥n
  
- [x] Sistema de demostraci√≥n formal
  - [x] Demostraci√≥n de que Hamming es m√©trica
  - [x] Verificador autom√°tico de pruebas
  - [x] Biblioteca de teoremas reutilizables
  
- [ ] Tests unitarios creados
  - [ ] Tests para `hamming_distance()`
  - [ ] Tests para propiedades m√©tricas
  - [ ] Tests para c√≥digos correctores
  - [ ] Tests de integraci√≥n

### Pr√≥ximas Mejoras

- [ ] Visualizaci√≥n de esferas de Hamming
- [ ] Implementaci√≥n de c√≥digos de Hamming (n,k) generales
- [ ] Algoritmos de decodificaci√≥n eficientes
- [ ] Comparaci√≥n de rendimiento con otras m√©tricas
- [ ] Integraci√≥n con m√≥dulos de c√≥digos especializados (BCD, Gray, etc.)

---

**√öltima actualizaci√≥n**: Enero 2026  
**Estado**: ‚úÖ Documentaci√≥n completa con demostraciones formales
